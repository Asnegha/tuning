| distributed init (rank 0): env://, gpu 0
[09:16:38.954786] job dir: /raid/speech/snegha/prompt_tuning/llama_adapter/LLaMA-Adapter/alpaca_finetuning_v1
[09:16:38.954982] Namespace(batch_size=16,
epochs=5,
accum_iter=1,
llama_model_path='model/LLaMA-7B/',
model='Llama7B_adapter',
adapter_layer=30,
adapter_len=10,
max_seq_len=512,
weight_decay=0.02,
lr=0.003,
blr=0.001,
min_lr=0.0,
warmup_epochs=0,
data_path='train_data_hindi.json',
output_dir='./checkpoint_hindi/',
log_dir='./output_dir',
device='cuda',
seed=0,
resume='',
start_epoch=0,
num_workers=10,
pin_mem=True,
world_size=1,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
rank=0,
gpu=0,
distributed=True,
dist_backend='nccl')
[09:16:41.063087] <__main__.InstructionDataset object at 0x7b00e1c15be0>
[09:16:41.063196] <__main__.InstructionDataset object at 0x7b00d7cf95b0>
[09:16:41.063283] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7b01b3e9b100>
[09:16:49.696351] model/LLaMA-7B//consolidated.00.pth
[09:16:52.627994] before tensor([ 0.9595, -1.0186, -0.8481,  0.8662,  0.5752,  0.8911,  2.1309, -0.2020,
         0.0273, -0.1974, -1.8271,  0.8550,  1.4365, -2.4609, -1.0205, -0.3181,
         0.0668, -1.0205, -0.3958, -0.5156, -0.9902,  0.7544, -1.0127, -0.2532,
         1.4873, -0.5283, -0.1315, -1.5303, -0.4106, -0.2196, -0.4819,  0.8408,
        -0.1748,  0.7041, -0.6504,  0.1998, -0.4763,  0.8594, -0.7812, -1.8701,
         1.2051,  0.1137,  1.1875, -2.3262, -0.0590, -0.0160,  0.3894,  1.6719,
        -1.6943,  0.6851,  0.9214, -0.1519, -0.1047, -0.2440, -0.0649,  1.1670,
        -0.3687,  0.7622,  0.8174,  1.1162, -1.3203, -0.9849, -0.5518,  0.3350,
        -1.4873, -2.7090,  0.4480,  1.0127, -0.6089,  0.5459,  1.0967,  1.7197,
        -1.4541,  1.0000,  0.6074,  2.3008,  1.1826,  0.5410,  1.2617,  0.6890,
         0.1127, -0.0465,  0.4167, -1.4033,  1.4189,  0.9946,  0.1852,  0.1962,
        -0.6353,  1.6953, -0.3777, -0.1997,  0.1530,  1.5889, -1.3457,  1.1514,
         0.1807, -1.1338, -0.1315, -0.2639,  0.3262,  0.3628, -0.4165,  0.2747,
        -2.4219,  0.6094,  0.7480,  0.7866, -0.4482, -0.4260, -0.1071,  1.3291,
         1.0977, -0.7358, -1.1484, -1.6699, -0.8960,  0.7285,  0.3044,  0.7134,
        -0.3215,  0.6455,  0.1552, -1.6084,  0.2117, -1.1299, -0.7910,  1.8027,
         1.0771,  2.2539,  0.0499, -1.0410, -0.0100, -0.9282,  0.6572, -0.1356,
        -0.1686, -0.8350, -0.5762, -0.4536, -0.8706,  0.1323,  0.2004,  2.5410,
         0.1331, -0.0954,  0.3496, -0.3103, -0.5703, -2.2383,  0.5767,  0.0640,
         0.4197,  0.3945, -1.1592,  0.7593, -0.7637, -0.5913,  1.3115,  0.7900,
        -1.6758,  0.2888, -0.3428,  2.7500,  0.3540, -0.8267,  1.0527,  0.0408,
        -0.1361, -0.7979,  1.3145,  1.1074,  1.1279, -1.0986,  1.7354, -0.7271,
         0.3013,  0.1631, -0.5503, -0.2791,  0.9600,  0.2188,  0.3813, -0.3435,
        -1.3955,  0.2903, -0.0842, -1.1631,  0.5801,  0.1855, -0.1356, -0.8862,
         0.2664,  0.4216, -1.5156,  0.3689, -0.9087, -1.2354, -0.3438,  0.9087,
        -0.2300,  0.8818,  0.7207, -1.4102, -0.4443,  0.4087,  1.2598, -0.3354,
        -0.3625,  0.6211,  0.8740, -1.6094,  2.1836, -0.4285,  0.2947, -0.4971,
        -0.2617,  0.5591, -1.1387,  0.4563,  1.2881,  1.5928,  1.2373, -0.0130,
        -0.2220,  0.4207,  1.5371,  0.2457, -1.5879,  0.3501,  0.4390,  0.7451,
         0.2499, -0.4124, -1.4043, -1.2852, -0.4409, -0.0537,  0.5933,  0.1447,
         0.0162,  0.3679,  0.8945, -1.3701, -0.4172,  0.4641,  2.7520,  0.9370,
         0.6445, -0.6440, -0.0337,  1.0742, -0.0538, -0.5278, -1.7207,  0.5713,
         1.8037, -0.4568, -0.1954,  0.5186,  1.5752, -0.8052, -0.6436, -0.3748,
        -1.0117,  0.3923,  0.6963, -0.1213,  0.1094, -0.2776, -0.6201, -1.8115,
        -0.8237, -0.2832, -0.7866, -0.7344,  0.3765, -0.9448, -0.9727, -0.5649,
         1.8145,  0.0542, -1.5117, -0.2747, -0.9399,  0.7075,  0.7559, -0.5454,
        -1.1045,  1.9092,  1.1494,  2.5156,  0.0151, -1.8936, -0.1420, -0.1428,
        -0.5386, -1.2881,  0.1127, -0.5259], device='cuda:0',
       grad_fn=<SelectBackward0>)
[09:16:52.718702] Model = Transformer(
  (tok_embeddings): Embedding(32000, 4096)
  (adapter_query): Embedding(300, 4096)
  (criterion): CrossEntropyLoss()
  (layers): ModuleList(
    (0-31): 32 x TransformerBlock(
      (attention): Attention(
        (wq): Linear(in_features=4096, out_features=4096, bias=False)
        (wk): Linear(in_features=4096, out_features=4096, bias=False)
        (wv): Linear(in_features=4096, out_features=4096, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=11008, bias=False)
        (w2): Linear(in_features=11008, out_features=4096, bias=False)
        (w3): Linear(in_features=4096, out_features=11008, bias=False)
      )
      (attention_norm): RMSNorm()
      (ffn_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=32000, bias=False)
)
[09:16:52.718811] base lr: 4.80e-02
[09:16:52.718829] actual lr: 3.00e-03
[09:16:52.718853] accumulate grad iterations: 1
[09:16:52.718868] effective batch size: 16
[09:16:52.752191] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.003
    maximize: False
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.003
    maximize: False
    weight_decay: 0.02
)
[09:16:52.752891] Start training for 5 epochs
[09:16:52.755396] log_dir: ./output_dir
[09:16:55.090050] Epoch: [0]  [   0/4188]  eta: 2:42:51  lr: 0.003000  closs: 0.8745 (0.8745)  time: 2.3332  data: 0.3422  max mem: 66945
[09:17:11.152681] Epoch: [0]  [  10/4188]  eta: 1:56:26  lr: 0.003000  closs: 0.8843 (0.8756)  time: 1.6722  data: 0.0312  max mem: 66975
[09:17:27.182030] Epoch: [0]  [  20/4188]  eta: 1:53:52  lr: 0.003000  closs: 0.8716 (0.8637)  time: 1.6045  data: 0.0002  max mem: 66975
[09:17:43.252837] Epoch: [0]  [  30/4188]  eta: 1:52:52  lr: 0.003000  closs: 0.8491 (0.8552)  time: 1.6049  data: 0.0002  max mem: 66975
[09:17:59.319094] Epoch: [0]  [  40/4188]  eta: 1:52:13  lr: 0.003000  closs: 0.8320 (0.8517)  time: 1.6068  data: 0.0002  max mem: 66975
[09:18:15.381529] Epoch: [0]  [  50/4188]  eta: 1:51:43  lr: 0.003000  closs: 0.8311 (0.8451)  time: 1.6064  data: 0.0002  max mem: 66975
[09:18:31.474575] Epoch: [0]  [  60/4188]  eta: 1:51:20  lr: 0.003000  closs: 0.8296 (0.8399)  time: 1.6077  data: 0.0002  max mem: 66975
[09:18:47.565653] Epoch: [0]  [  70/4188]  eta: 1:50:58  lr: 0.003000  closs: 0.8345 (0.8405)  time: 1.6091  data: 0.0002  max mem: 66975
[09:19:03.668514] Epoch: [0]  [  80/4188]  eta: 1:50:38  lr: 0.003000  closs: 0.8311 (0.8378)  time: 1.6096  data: 0.0001  max mem: 66975
[09:19:19.743809] Epoch: [0]  [  90/4188]  eta: 1:50:18  lr: 0.003000  closs: 0.8169 (0.8349)  time: 1.6088  data: 0.0001  max mem: 66975
[09:19:35.821919] Epoch: [0]  [ 100/4188]  eta: 1:49:59  lr: 0.003000  closs: 0.8335 (0.8363)  time: 1.6076  data: 0.0001  max mem: 66975
[09:19:51.981148] Epoch: [0]  [ 110/4188]  eta: 1:49:44  lr: 0.003000  closs: 0.8066 (0.8313)  time: 1.6118  data: 0.0002  max mem: 66975
[09:20:08.211093] Epoch: [0]  [ 120/4188]  eta: 1:49:30  lr: 0.003000  closs: 0.7729 (0.8268)  time: 1.6194  data: 0.0002  max mem: 66975
[09:20:24.381125] Epoch: [0]  [ 130/4188]  eta: 1:49:15  lr: 0.003000  closs: 0.7827 (0.8250)  time: 1.6199  data: 0.0002  max mem: 66975
[09:20:40.689612] Epoch: [0]  [ 140/4188]  eta: 1:49:03  lr: 0.003000  closs: 0.7925 (0.8232)  time: 1.6238  data: 0.0004  max mem: 66975
[09:20:56.894360] Epoch: [0]  [ 150/4188]  eta: 1:48:48  lr: 0.003000  closs: 0.7695 (0.8196)  time: 1.6256  data: 0.0003  max mem: 66975
[09:21:13.381655] Epoch: [0]  [ 160/4188]  eta: 1:48:40  lr: 0.003000  closs: 0.7769 (0.8202)  time: 1.6345  data: 0.0009  max mem: 66975
[09:21:29.535760] Epoch: [0]  [ 170/4188]  eta: 1:48:23  lr: 0.003000  closs: 0.8359 (0.8218)  time: 1.6320  data: 0.0012  max mem: 66975
[09:21:45.649985] Epoch: [0]  [ 180/4188]  eta: 1:48:05  lr: 0.002999  closs: 0.8301 (0.8211)  time: 1.6133  data: 0.0005  max mem: 66975
[09:22:01.709915] Epoch: [0]  [ 190/4188]  eta: 1:47:46  lr: 0.002999  closs: 0.7979 (0.8212)  time: 1.6086  data: 0.0001  max mem: 66975
[09:22:17.779817] Epoch: [0]  [ 200/4188]  eta: 1:47:28  lr: 0.002999  closs: 0.7866 (0.8180)  time: 1.6064  data: 0.0001  max mem: 66975
[09:22:33.850886] Epoch: [0]  [ 210/4188]  eta: 1:47:10  lr: 0.002999  closs: 0.7827 (0.8176)  time: 1.6070  data: 0.0001  max mem: 66975
[09:22:49.928622] Epoch: [0]  [ 220/4188]  eta: 1:46:52  lr: 0.002999  closs: 0.8115 (0.8176)  time: 1.6074  data: 0.0001  max mem: 66975
[09:23:06.019763] Epoch: [0]  [ 230/4188]  eta: 1:46:35  lr: 0.002999  closs: 0.7964 (0.8161)  time: 1.6084  data: 0.0001  max mem: 66975
[09:23:22.127855] Epoch: [0]  [ 240/4188]  eta: 1:46:18  lr: 0.002999  closs: 0.7964 (0.8152)  time: 1.6099  data: 0.0001  max mem: 66975
[09:23:38.245533] Epoch: [0]  [ 250/4188]  eta: 1:46:01  lr: 0.002999  closs: 0.7954 (0.8140)  time: 1.6112  data: 0.0001  max mem: 66975
[09:23:54.339147] Epoch: [0]  [ 260/4188]  eta: 1:45:44  lr: 0.002999  closs: 0.7871 (0.8139)  time: 1.6105  data: 0.0001  max mem: 66975
[09:24:10.427157] Epoch: [0]  [ 270/4188]  eta: 1:45:27  lr: 0.002999  closs: 0.7832 (0.8133)  time: 1.6090  data: 0.0001  max mem: 66975
[09:24:26.601272] Epoch: [0]  [ 280/4188]  eta: 1:45:11  lr: 0.002999  closs: 0.7930 (0.8127)  time: 1.6127  data: 0.0001  max mem: 66975
[09:24:42.973739] Epoch: [0]  [ 290/4188]  eta: 1:44:58  lr: 0.002999  closs: 0.7964 (0.8127)  time: 1.6269  data: 0.0003  max mem: 66975
[09:24:59.192531] Epoch: [0]  [ 300/4188]  eta: 1:44:42  lr: 0.002998  closs: 0.7559 (0.8110)  time: 1.6294  data: 0.0004  max mem: 66975
[09:25:15.430000] Epoch: [0]  [ 310/4188]  eta: 1:44:27  lr: 0.002998  closs: 0.7656 (0.8113)  time: 1.6226  data: 0.0003  max mem: 66975
[09:25:31.594583] Epoch: [0]  [ 320/4188]  eta: 1:44:11  lr: 0.002998  closs: 0.7993 (0.8110)  time: 1.6199  data: 0.0002  max mem: 66975
[09:25:47.953349] Epoch: [0]  [ 330/4188]  eta: 1:43:57  lr: 0.002998  closs: 0.8130 (0.8110)  time: 1.6260  data: 0.0003  max mem: 66975
[09:26:04.137130] Epoch: [0]  [ 340/4188]  eta: 1:43:41  lr: 0.002998  closs: 0.8140 (0.8115)  time: 1.6270  data: 0.0005  max mem: 66975
[09:26:20.247960] Epoch: [0]  [ 350/4188]  eta: 1:43:24  lr: 0.002998  closs: 0.8086 (0.8110)  time: 1.6147  data: 0.0003  max mem: 66975
[09:26:36.341293] Epoch: [0]  [ 360/4188]  eta: 1:43:07  lr: 0.002998  closs: 0.7847 (0.8101)  time: 1.6101  data: 0.0001  max mem: 66975
[09:26:52.435948] Epoch: [0]  [ 370/4188]  eta: 1:42:50  lr: 0.002998  closs: 0.7554 (0.8091)  time: 1.6093  data: 0.0001  max mem: 66975
[09:27:08.543544] Epoch: [0]  [ 380/4188]  eta: 1:42:34  lr: 0.002998  closs: 0.7554 (0.8080)  time: 1.6100  data: 0.0001  max mem: 66975
[09:27:24.654300] Epoch: [0]  [ 390/4188]  eta: 1:42:17  lr: 0.002997  closs: 0.7471 (0.8077)  time: 1.6108  data: 0.0001  max mem: 66975
[09:27:40.768015] Epoch: [0]  [ 400/4188]  eta: 1:42:00  lr: 0.002997  closs: 0.7959 (0.8073)  time: 1.6111  data: 0.0001  max mem: 66975
[09:27:56.848567] Epoch: [0]  [ 410/4188]  eta: 1:41:44  lr: 0.002997  closs: 0.7847 (0.8069)  time: 1.6096  data: 0.0002  max mem: 66975
[09:28:12.945612] Epoch: [0]  [ 420/4188]  eta: 1:41:27  lr: 0.002997  closs: 0.8047 (0.8070)  time: 1.6088  data: 0.0001  max mem: 66975
[09:28:29.040063] Epoch: [0]  [ 430/4188]  eta: 1:41:10  lr: 0.002997  closs: 0.8042 (0.8068)  time: 1.6095  data: 0.0001  max mem: 66975
[09:28:45.148094] Epoch: [0]  [ 440/4188]  eta: 1:40:54  lr: 0.002997  closs: 0.7964 (0.8063)  time: 1.6101  data: 0.0001  max mem: 66975
[09:29:01.338953] Epoch: [0]  [ 450/4188]  eta: 1:40:38  lr: 0.002997  closs: 0.7715 (0.8053)  time: 1.6149  data: 0.0003  max mem: 66975
[09:29:17.576228] Epoch: [0]  [ 460/4188]  eta: 1:40:22  lr: 0.002996  closs: 0.7524 (0.8050)  time: 1.6213  data: 0.0004  max mem: 66975
[09:29:33.759416] Epoch: [0]  [ 470/4188]  eta: 1:40:06  lr: 0.002996  closs: 0.8018 (0.8051)  time: 1.6209  data: 0.0002  max mem: 66975
[09:29:49.921909] Epoch: [0]  [ 480/4188]  eta: 1:39:50  lr: 0.002996  closs: 0.7920 (0.8046)  time: 1.6171  data: 0.0002  max mem: 66975
[09:30:06.051085] Epoch: [0]  [ 490/4188]  eta: 1:39:34  lr: 0.002996  closs: 0.7583 (0.8034)  time: 1.6144  data: 0.0002  max mem: 66975
[09:30:22.212749] Epoch: [0]  [ 500/4188]  eta: 1:39:18  lr: 0.002996  closs: 0.7520 (0.8028)  time: 1.6144  data: 0.0003  max mem: 66975
[09:30:38.336385] Epoch: [0]  [ 510/4188]  eta: 1:39:01  lr: 0.002996  closs: 0.7729 (0.8022)  time: 1.6142  data: 0.0002  max mem: 66975
[09:30:54.445393] Epoch: [0]  [ 520/4188]  eta: 1:38:45  lr: 0.002995  closs: 0.7744 (0.8021)  time: 1.6115  data: 0.0001  max mem: 66975
[09:31:10.550171] Epoch: [0]  [ 530/4188]  eta: 1:38:28  lr: 0.002995  closs: 0.7749 (0.8020)  time: 1.6106  data: 0.0001  max mem: 66975
[09:31:26.650585] Epoch: [0]  [ 540/4188]  eta: 1:38:12  lr: 0.002995  closs: 0.7886 (0.8018)  time: 1.6102  data: 0.0001  max mem: 66975
[09:31:42.743221] Epoch: [0]  [ 550/4188]  eta: 1:37:55  lr: 0.002995  closs: 0.7715 (0.8013)  time: 1.6096  data: 0.0001  max mem: 66975
[09:31:58.833892] Epoch: [0]  [ 560/4188]  eta: 1:37:39  lr: 0.002995  closs: 0.7715 (0.8008)  time: 1.6091  data: 0.0001  max mem: 66975
[09:32:14.936774] Epoch: [0]  [ 570/4188]  eta: 1:37:22  lr: 0.002995  closs: 0.7817 (0.8001)  time: 1.6096  data: 0.0001  max mem: 66975
[09:32:31.030299] Epoch: [0]  [ 580/4188]  eta: 1:37:06  lr: 0.002994  closs: 0.7764 (0.7998)  time: 1.6097  data: 0.0001  max mem: 66975
[09:32:47.126834] Epoch: [0]  [ 590/4188]  eta: 1:36:49  lr: 0.002994  closs: 0.7788 (0.7992)  time: 1.6094  data: 0.0001  max mem: 66975
[09:33:03.222934] Epoch: [0]  [ 600/4188]  eta: 1:36:33  lr: 0.002994  closs: 0.7788 (0.7989)  time: 1.6095  data: 0.0001  max mem: 66975
[09:33:19.334153] Epoch: [0]  [ 610/4188]  eta: 1:36:16  lr: 0.002994  closs: 0.7437 (0.7983)  time: 1.6103  data: 0.0002  max mem: 66975
[09:33:35.437553] Epoch: [0]  [ 620/4188]  eta: 1:36:00  lr: 0.002994  closs: 0.7671 (0.7987)  time: 1.6106  data: 0.0002  max mem: 66975
[09:33:51.600676] Epoch: [0]  [ 630/4188]  eta: 1:35:44  lr: 0.002993  closs: 0.8291 (0.7986)  time: 1.6132  data: 0.0002  max mem: 66975
[09:34:07.695069] Epoch: [0]  [ 640/4188]  eta: 1:35:28  lr: 0.002993  closs: 0.7866 (0.7986)  time: 1.6128  data: 0.0002  max mem: 66975
[09:34:23.839753] Epoch: [0]  [ 650/4188]  eta: 1:35:11  lr: 0.002993  closs: 0.7705 (0.7983)  time: 1.6118  data: 0.0001  max mem: 66975
[09:34:39.934692] Epoch: [0]  [ 660/4188]  eta: 1:34:55  lr: 0.002993  closs: 0.7637 (0.7979)  time: 1.6119  data: 0.0001  max mem: 66975
[09:34:56.076074] Epoch: [0]  [ 670/4188]  eta: 1:34:39  lr: 0.002992  closs: 0.8037 (0.7983)  time: 1.6117  data: 0.0001  max mem: 66975
[09:35:12.172281] Epoch: [0]  [ 680/4188]  eta: 1:34:22  lr: 0.002992  closs: 0.8115 (0.7983)  time: 1.6118  data: 0.0001  max mem: 66975
[09:35:28.277651] Epoch: [0]  [ 690/4188]  eta: 1:34:06  lr: 0.002992  closs: 0.7617 (0.7978)  time: 1.6100  data: 0.0001  max mem: 66975
[09:35:44.356856] Epoch: [0]  [ 700/4188]  eta: 1:33:50  lr: 0.002992  closs: 0.7603 (0.7974)  time: 1.6092  data: 0.0001  max mem: 66975
[09:36:00.444329] Epoch: [0]  [ 710/4188]  eta: 1:33:33  lr: 0.002991  closs: 0.7671 (0.7970)  time: 1.6083  data: 0.0001  max mem: 66975
[09:36:16.534329] Epoch: [0]  [ 720/4188]  eta: 1:33:17  lr: 0.002991  closs: 0.7681 (0.7968)  time: 1.6088  data: 0.0001  max mem: 66975
[09:36:32.657206] Epoch: [0]  [ 730/4188]  eta: 1:33:01  lr: 0.002991  closs: 0.7798 (0.7967)  time: 1.6106  data: 0.0001  max mem: 66975
[09:36:48.755136] Epoch: [0]  [ 740/4188]  eta: 1:32:44  lr: 0.002991  closs: 0.7944 (0.7970)  time: 1.6110  data: 0.0001  max mem: 66975
[09:37:04.850183] Epoch: [0]  [ 750/4188]  eta: 1:32:28  lr: 0.002991  closs: 0.7944 (0.7967)  time: 1.6096  data: 0.0001  max mem: 66975
[09:37:20.936474] Epoch: [0]  [ 760/4188]  eta: 1:32:12  lr: 0.002990  closs: 0.7456 (0.7963)  time: 1.6090  data: 0.0001  max mem: 66975
[09:37:37.024403] Epoch: [0]  [ 770/4188]  eta: 1:31:55  lr: 0.002990  closs: 0.7720 (0.7964)  time: 1.6086  data: 0.0001  max mem: 66975
[09:37:53.134693] Epoch: [0]  [ 780/4188]  eta: 1:31:39  lr: 0.002990  closs: 0.7686 (0.7957)  time: 1.6098  data: 0.0001  max mem: 66975
[09:38:09.312657] Epoch: [0]  [ 790/4188]  eta: 1:31:23  lr: 0.002989  closs: 0.7227 (0.7947)  time: 1.6143  data: 0.0002  max mem: 66975
[09:38:25.489149] Epoch: [0]  [ 800/4188]  eta: 1:31:07  lr: 0.002989  closs: 0.7759 (0.7947)  time: 1.6176  data: 0.0002  max mem: 66975
[09:38:41.629836] Epoch: [0]  [ 810/4188]  eta: 1:30:51  lr: 0.002989  closs: 0.7764 (0.7944)  time: 1.6158  data: 0.0002  max mem: 66975
[09:38:57.754375] Epoch: [0]  [ 820/4188]  eta: 1:30:35  lr: 0.002989  closs: 0.7725 (0.7941)  time: 1.6132  data: 0.0001  max mem: 66975
[09:39:13.981526] Epoch: [0]  [ 830/4188]  eta: 1:30:19  lr: 0.002988  closs: 0.7734 (0.7940)  time: 1.6175  data: 0.0002  max mem: 66975
[09:39:30.111951] Epoch: [0]  [ 840/4188]  eta: 1:30:03  lr: 0.002988  closs: 0.7881 (0.7940)  time: 1.6178  data: 0.0002  max mem: 66975
[09:39:46.209899] Epoch: [0]  [ 850/4188]  eta: 1:29:46  lr: 0.002988  closs: 0.7676 (0.7936)  time: 1.6113  data: 0.0001  max mem: 66975
[09:40:02.294187] Epoch: [0]  [ 860/4188]  eta: 1:29:30  lr: 0.002988  closs: 0.7573 (0.7930)  time: 1.6090  data: 0.0001  max mem: 66975
[09:40:18.401793] Epoch: [0]  [ 870/4188]  eta: 1:29:14  lr: 0.002987  closs: 0.7568 (0.7929)  time: 1.6095  data: 0.0001  max mem: 66975
[09:40:34.497330] Epoch: [0]  [ 880/4188]  eta: 1:28:58  lr: 0.002987  closs: 0.7686 (0.7928)  time: 1.6101  data: 0.0001  max mem: 66975
[09:40:50.603206] Epoch: [0]  [ 890/4188]  eta: 1:28:41  lr: 0.002987  closs: 0.7686 (0.7928)  time: 1.6100  data: 0.0001  max mem: 66975
[09:41:06.694206] Epoch: [0]  [ 900/4188]  eta: 1:28:25  lr: 0.002986  closs: 0.7627 (0.7923)  time: 1.6098  data: 0.0001  max mem: 66975
[09:41:22.796507] Epoch: [0]  [ 910/4188]  eta: 1:28:09  lr: 0.002986  closs: 0.7656 (0.7922)  time: 1.6096  data: 0.0001  max mem: 66975
[09:41:38.891701] Epoch: [0]  [ 920/4188]  eta: 1:27:52  lr: 0.002986  closs: 0.7944 (0.7922)  time: 1.6098  data: 0.0001  max mem: 66975
[09:41:55.000907] Epoch: [0]  [ 930/4188]  eta: 1:27:36  lr: 0.002985  closs: 0.7715 (0.7918)  time: 1.6101  data: 0.0001  max mem: 66975
[09:42:11.093249] Epoch: [0]  [ 940/4188]  eta: 1:27:20  lr: 0.002985  closs: 0.7534 (0.7917)  time: 1.6100  data: 0.0001  max mem: 66975
[09:42:27.189551] Epoch: [0]  [ 950/4188]  eta: 1:27:04  lr: 0.002985  closs: 0.7969 (0.7917)  time: 1.6094  data: 0.0001  max mem: 66975
[09:42:43.578938] Epoch: [0]  [ 960/4188]  eta: 1:26:48  lr: 0.002984  closs: 0.7964 (0.7914)  time: 1.6242  data: 0.0005  max mem: 66975
[09:42:59.747911] Epoch: [0]  [ 970/4188]  eta: 1:26:32  lr: 0.002984  closs: 0.7515 (0.7910)  time: 1.6278  data: 0.0006  max mem: 66975
[09:43:15.943902] Epoch: [0]  [ 980/4188]  eta: 1:26:16  lr: 0.002984  closs: 0.7515 (0.7907)  time: 1.6182  data: 0.0002  max mem: 66975
[09:43:32.088259] Epoch: [0]  [ 990/4188]  eta: 1:26:00  lr: 0.002983  closs: 0.7427 (0.7905)  time: 1.6169  data: 0.0001  max mem: 66975
[09:43:48.446426] Epoch: [0]  [1000/4188]  eta: 1:25:45  lr: 0.002983  closs: 0.7388 (0.7899)  time: 1.6250  data: 0.0001  max mem: 66975
[09:44:04.690157] Epoch: [0]  [1010/4188]  eta: 1:25:29  lr: 0.002983  closs: 0.7554 (0.7897)  time: 1.6300  data: 0.0002  max mem: 66975
[09:44:20.868939] Epoch: [0]  [1020/4188]  eta: 1:25:13  lr: 0.002982  closs: 0.7764 (0.7897)  time: 1.6210  data: 0.0002  max mem: 66975
[09:44:36.954992] Epoch: [0]  [1030/4188]  eta: 1:24:57  lr: 0.002982  closs: 0.7666 (0.7893)  time: 1.6132  data: 0.0001  max mem: 66975
[09:44:53.063799] Epoch: [0]  [1040/4188]  eta: 1:24:40  lr: 0.002982  closs: 0.7354 (0.7888)  time: 1.6097  data: 0.0001  max mem: 66975
